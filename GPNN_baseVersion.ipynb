{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFiJES_JkIc6"
      },
      "source": [
        "### Для запуска"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjmYRaY7GLaI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random \n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn,manual_seed,from_numpy, split, tensor\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHqFgbzw_qLq",
        "outputId": "fa843e2a-a38d-41bd-91ec-ffc66b8a1898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_nSjBowGc2s",
        "outputId": "475b963c-e520-4414-8ef4-f1a4ac11ce17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz0Cdpc1TiD2"
      },
      "source": [
        "Далее идут две функции, которые нужны для перевода данных в тензор."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMIfITyzGVdY"
      },
      "outputs": [],
      "source": [
        "def dataConvertor(data,device):\n",
        "    inputData = []\n",
        "    outputData = []\n",
        "    classVectors = []\n",
        "    for i in data:\n",
        "        inputData.append(i[0])\n",
        "        classVectors.append(i[1])\n",
        "        outputData.append(i[2])\n",
        "    return  tensor(inputData).to(device),tensor(classVectors).to(device),tensor(outputData).to(device)\n",
        "\n",
        "\n",
        "def dataBatching(data,batch_len=1):\n",
        "    inputData =  split(data[0],batch_len)\n",
        "    classVectors = split(data[1],batch_len)\n",
        "    outputData = split(data[2],batch_len)\n",
        "    batchedData = []\n",
        "    for i in range(len(inputData)):\n",
        "        batchedData.append([inputData[i],classVectors[i],outputData[i]])\n",
        "    return batchedData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7-jQN4JGdgk"
      },
      "outputs": [],
      "source": [
        "load_testData = np.load(\"/content/gdrive/MyDrive/Data_art_NN/Datasets/forRegression_allClass_test_500000.npy\",allow_pickle=True)\n",
        "load_trainData = np.load(\"/content/gdrive/MyDrive/Data_art_NN/Datasets/forRegression_allClass_train_500000.npy\",allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chgiInN0d1pK"
      },
      "outputs": [],
      "source": [
        "trainData = dataBatching(dataConvertor(load_trainData,device),500)\n",
        "testData = dataBatching(dataConvertor(load_testData,device),500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcafwI_kjbYT"
      },
      "outputs": [],
      "source": [
        "for batch,_ in enumerate(testData):\n",
        "  for i in range(500):\n",
        "    testData[batch][2][i][1] = (testData[batch][2][i][1]  + torch.tensor(np.pi/2))/np.pi\n",
        "    testData[batch][2][i][3] = (testData[batch][2][i][3]  + torch.tensor(np.pi/2))/np.pi\n",
        "    testData[batch][2][i][4] = (testData[batch][2][i][4])/(2*np.pi)\n",
        "    testData[batch][2][i][5] = (testData[batch][2][i][5]  + torch.tensor(1.))/2\n",
        "    testData[batch][2][i][6] = (testData[batch][2][i][6])/(2*np.pi)\n",
        "    trainData[batch][2][i][1] = (trainData[batch][2][i][1]  + torch.tensor(np.pi/2))/np.pi\n",
        "    trainData[batch][2][i][3] = (trainData[batch][2][i][3]  + torch.tensor(np.pi/2))/np.pi\n",
        "    trainData[batch][2][i][4] = (trainData[batch][2][i][4])/(2*np.pi)\n",
        "    trainData[batch][2][i][5] = (trainData[batch][2][i][5]  + torch.tensor(1.))/2\n",
        "    trainData[batch][2][i][6] = (trainData[batch][2][i][6])/(2*np.pi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbvI1ICQdrfs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "2c6KEyTsmFJb",
        "outputId": "c8c3744f-6f20-4c2e-a158-1fd0f9b4ab06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor(0.4201), tensor(0.0208), tensor(0.9665), tensor(0.1097), tensor(0.1746), tensor(0.6495), tensor(0.3985), tensor(0.5002), tensor(0.2312), tensor(0.6515), tensor(0.5577), tensor(0.0541), tensor(0.8643), tensor(0.6504), tensor(0.1162), tensor(0.7374), tensor(0.0096), tensor(0.5300), tensor(0.0713), tensor(0.2704), tensor(0.6355), tensor(0.7839), tensor(0.7065), tensor(0.3558), tensor(0.6860), tensor(0.8940), tensor(0.0340), tensor(0.4359), tensor(0.8887), tensor(0.1268), tensor(0.7846), tensor(0.7029), tensor(0.1682), tensor(0.7664), tensor(0.7704), tensor(0.9217), tensor(0.8428), tensor(0.9576), tensor(0.8348), tensor(0.6653), tensor(0.2295), tensor(0.0390), tensor(0.8698), tensor(0.1688), tensor(0.6625), tensor(0.9468), tensor(0.4337), tensor(0.2473), tensor(0.8747), tensor(0.3379), tensor(0.6277), tensor(0.7498), tensor(0.0877), tensor(0.0227), tensor(0.8363), tensor(0.7133), tensor(0.5076), tensor(0.8806), tensor(0.7723), tensor(0.5784), tensor(0.3737), tensor(0.6410), tensor(0.4416), tensor(0.0104), tensor(0.7120), tensor(0.8347), tensor(0.6052), tensor(0.7665), tensor(0.0283), tensor(0.0179), tensor(0.2083), tensor(0.4698), tensor(0.1594), tensor(0.5433), tensor(0.3869), tensor(0.2090), tensor(0.5304), tensor(0.8872), tensor(0.6479), tensor(0.9207), tensor(0.6767), tensor(0.7211), tensor(0.8231), tensor(0.8539), tensor(0.9274), tensor(0.0118), tensor(0.1865), tensor(0.4113), tensor(0.3006), tensor(0.0388), tensor(0.0205), tensor(0.3595), tensor(0.5351), tensor(0.9369), tensor(0.1296), tensor(0.8018), tensor(0.5242), tensor(0.1500), tensor(0.9130), tensor(0.3397), tensor(0.7896), tensor(0.4243), tensor(0.2913), tensor(0.4951), tensor(0.4410), tensor(0.0918), tensor(0.4943), tensor(0.3750), tensor(0.3694), tensor(0.1826), tensor(0.1124), tensor(0.6704), tensor(0.1625), tensor(0.8036), tensor(0.4688), tensor(0.5133), tensor(0.6762), tensor(0.9491), tensor(0.4121), tensor(0.1720), tensor(0.5785), tensor(0.8838), tensor(0.6624), tensor(0.0402), tensor(0.4721), tensor(0.7802), tensor(0.6428), tensor(0.9474), tensor(0.4574), tensor(0.7269), tensor(0.1548), tensor(0.7938), tensor(0.9377), tensor(0.9207), tensor(0.2829), tensor(0.0902), tensor(0.6185), tensor(0.3574), tensor(0.6631), tensor(0.2527), tensor(0.2881), tensor(0.8140), tensor(0.9863), tensor(0.6456), tensor(0.4024), tensor(0.4751), tensor(0.4279), tensor(0.1750), tensor(0.3247), tensor(0.8152), tensor(0.9294), tensor(0.5217), tensor(0.6053), tensor(0.5345), tensor(0.4438), tensor(0.4205), tensor(0.0916), tensor(0.9984), tensor(0.0166), tensor(0.7882), tensor(0.3656), tensor(0.6713), tensor(0.6883), tensor(0.5506), tensor(0.8151), tensor(0.6647), tensor(0.3793), tensor(0.2706), tensor(0.2369), tensor(0.0538), tensor(0.3271), tensor(0.1040), tensor(0.0237), tensor(0.4221), tensor(0.6967), tensor(0.3784), tensor(0.8769), tensor(0.2875), tensor(0.0371), tensor(0.1017), tensor(0.2332), tensor(0.7125), tensor(0.6645), tensor(0.9953), tensor(0.7177), tensor(0.5536), tensor(0.7193), tensor(0.1528), tensor(0.7030), tensor(0.9963), tensor(0.5930), tensor(0.1936), tensor(0.7516), tensor(0.9497), tensor(0.3205), tensor(0.5561), tensor(0.4637), tensor(0.7881), tensor(0.3121), tensor(0.0599), tensor(0.0607), tensor(0.5569), tensor(0.8880), tensor(0.4684), tensor(0.5037), tensor(0.5993), tensor(0.0545), tensor(0.0042), tensor(0.2071), tensor(0.5677), tensor(0.3953), tensor(0.5730), tensor(0.4901), tensor(0.0013), tensor(0.5351), tensor(0.8454), tensor(0.4553), tensor(0.6929), tensor(0.3898), tensor(0.6565), tensor(0.8346), tensor(0.7604), tensor(0.3564), tensor(0.9007), tensor(0.4779), tensor(0.1071), tensor(0.8930), tensor(0.1240), tensor(0.9330), tensor(0.6365), tensor(0.4587), tensor(0.6696), tensor(0.3408), tensor(0.6969), tensor(0.0296), tensor(0.5489), tensor(0.8680), tensor(0.3481), tensor(0.6162), tensor(0.7770), tensor(0.5719), tensor(0.7245), tensor(0.3337), tensor(0.5402), tensor(0.2906), tensor(0.3251), tensor(0.2834), tensor(0.0347), tensor(0.6350), tensor(0.8535), tensor(0.8037), tensor(0.3334), tensor(0.1498), tensor(0.2962), tensor(0.7337), tensor(0.0682), tensor(0.0532), tensor(0.5816), tensor(0.3297), tensor(0.2382), tensor(0.3478), tensor(0.2126), tensor(0.9063), tensor(0.1638), tensor(0.0297), tensor(0.1591), tensor(0.3801), tensor(0.7345), tensor(0.0789), tensor(0.4451), tensor(0.4920), tensor(0.8594), tensor(0.5964), tensor(0.9742), tensor(0.1346), tensor(0.4221), tensor(0.3709), tensor(0.5163), tensor(0.2440), tensor(0.8603), tensor(0.5942), tensor(0.4666), tensor(0.2294), tensor(0.6182), tensor(0.2173), tensor(0.2508), tensor(0.7409), tensor(0.0558), tensor(0.8509), tensor(0.7079), tensor(0.7900), tensor(0.5198), tensor(0.7338), tensor(0.6531), tensor(0.0385), tensor(0.7356), tensor(0.5547), tensor(0.2801), tensor(0.6701), tensor(0.2888), tensor(0.0715), tensor(0.1121), tensor(0.2977), tensor(0.9876), tensor(0.4616), tensor(0.0688), tensor(0.4548), tensor(0.0663), tensor(0.7874), tensor(0.9908), tensor(0.9434), tensor(0.5118), tensor(0.8684), tensor(0.3569), tensor(0.7759), tensor(0.0873), tensor(0.4428), tensor(0.4669), tensor(0.0250), tensor(0.4618), tensor(0.3126), tensor(0.9437), tensor(0.7887), tensor(0.3056), tensor(0.5479), tensor(0.1612), tensor(0.6940), tensor(0.1550), tensor(0.6949), tensor(0.8661), tensor(0.9375), tensor(0.8050), tensor(0.0900), tensor(0.9446), tensor(0.6618), tensor(0.8382), tensor(0.0012), tensor(0.2615), tensor(0.8408), tensor(0.7838), tensor(0.6894), tensor(0.2430), tensor(0.0633), tensor(0.1587), tensor(0.7090), tensor(0.1749), tensor(0.1728), tensor(0.5700), tensor(0.3036), tensor(0.6948), tensor(0.8005), tensor(0.4229), tensor(0.8785), tensor(0.5787), tensor(0.1023), tensor(0.0184), tensor(0.3268), tensor(0.2212), tensor(0.2880), tensor(0.1972), tensor(0.3179), tensor(0.2600), tensor(0.5883), tensor(0.2475), tensor(0.7007), tensor(0.3466), tensor(0.7156), tensor(0.2751), tensor(0.4006), tensor(0.8611), tensor(0.7973), tensor(0.0894), tensor(0.0889), tensor(0.2650), tensor(0.2658), tensor(0.3485), tensor(0.8544), tensor(0.6317), tensor(0.0433), tensor(0.2023), tensor(0.8930), tensor(0.2598), tensor(0.3784), tensor(0.5755), tensor(0.7955), tensor(0.5988), tensor(0.8363), tensor(0.9131), tensor(0.5342), tensor(0.3032), tensor(0.6421), tensor(0.7733), tensor(0.5581), tensor(0.7251), tensor(0.6015), tensor(0.6659), tensor(0.7072), tensor(0.1765), tensor(0.7696), tensor(0.4579), tensor(0.3804), tensor(0.1955), tensor(0.0968), tensor(0.5580), tensor(0.3234), tensor(0.6492), tensor(0.0332), tensor(0.2322), tensor(0.5467), tensor(0.4882), tensor(0.8513), tensor(0.8363), tensor(0.4111), tensor(0.7702), tensor(0.6686), tensor(0.6783), tensor(0.3326), tensor(0.8771), tensor(0.1359), tensor(0.5222), tensor(0.6605), tensor(0.3268), tensor(0.4896), tensor(0.0048), tensor(0.4377), tensor(0.9113), tensor(0.3225), tensor(0.5875), tensor(0.8600), tensor(0.2886), tensor(0.9990), tensor(0.7283), tensor(0.5655), tensor(0.1202), tensor(0.4463), tensor(0.3413), tensor(0.7112), tensor(0.0133), tensor(0.5766), tensor(0.1902), tensor(0.2098), tensor(0.4288), tensor(0.4527), tensor(0.0114), tensor(0.3847), tensor(0.9061), tensor(0.0862), tensor(0.4497), tensor(0.3200), tensor(0.2007), tensor(0.7983), tensor(0.5295), tensor(0.4904), tensor(0.6822), tensor(0.6906), tensor(0.5027), tensor(0.5886), tensor(0.5779), tensor(0.6827), tensor(0.5658), tensor(0.4790), tensor(0.2679), tensor(0.1429), tensor(0.6502), tensor(0.4019), tensor(0.3216), tensor(0.4996), tensor(0.0072), tensor(0.6064), tensor(0.8758), tensor(0.3119), tensor(0.9561), tensor(0.1741), tensor(0.1833), tensor(0.1389), tensor(0.0883), tensor(0.4556), tensor(0.4306), tensor(0.1421), tensor(0.8945), tensor(0.1325), tensor(0.0112), tensor(0.8855), tensor(0.2447), tensor(0.1984), tensor(0.5239), tensor(0.2803), tensor(0.9877), tensor(0.4653), tensor(0.6454), tensor(0.8257), tensor(0.3489), tensor(0.9651), tensor(0.2906), tensor(0.4392), tensor(0.3164), tensor(0.4449), tensor(0.0720), tensor(0.9004), tensor(0.0587)]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([58., 46., 46., 52., 55., 53., 54., 51., 49., 36.]),\n",
              " array([0.00116342, 0.10094683, 0.20073023, 0.30051363, 0.40029705,\n",
              "        0.50008047, 0.5998638 , 0.69964725, 0.79943067, 0.899214  ,\n",
              "        0.99899745], dtype=float32),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "a = [i[5] for i in trainData[0][2][0:500]]\n",
        "print(a)\n",
        "plt.hist(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXTzNuROKczY",
        "outputId": "fed465c1-e14a-430e-860a-2150635dbbdf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([500, 7])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainData[0][2].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOM3vBc7kRBO"
      },
      "source": [
        "### Сеть"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUsqYbFflHu6"
      },
      "outputs": [],
      "source": [
        "baseSeq_regression = nn.Sequential(\n",
        "     nn.Linear(9, 300),\n",
        "     nn.ReLU(),\n",
        "     nn.BatchNorm1d(300),\n",
        "     nn.Linear(300, 3000),\n",
        "     nn.Dropout(0.6),\n",
        "     nn.ReLU(),\n",
        "     nn.BatchNorm1d(3000),\n",
        "     nn.Linear(3000, 6000),\n",
        "     nn.Dropout(0.6),\n",
        "     nn.ReLU(),\n",
        "     nn.BatchNorm1d(6000),\n",
        "     nn.Linear(6000, 3000),\n",
        "     nn.Dropout(0.6),\n",
        "     nn.ReLU(),\n",
        "     nn.BatchNorm1d(3000),\n",
        "     nn.Linear(3000, 1000),\n",
        "     nn.Dropout(0.6),\n",
        "     nn.ReLU(),\n",
        "     nn.BatchNorm1d(1000),\n",
        "     nn.Linear(1000, 100),\n",
        "     nn.ReLU(),\n",
        "     nn.BatchNorm1d(100)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLfTKU2IGq23"
      },
      "outputs": [],
      "source": [
        "class GPNN_regression(nn.Module):\n",
        "    def __init__(self, Seq = baseSeq_regression,init_form = 'normal'):\n",
        "        super().__init__()\n",
        "        self.layers_stack = Seq\n",
        "        self.fc_end_T = nn.Linear(100, 7)\n",
        "        #self.fc_end_LAA = nn.Linear(70, 3)\n",
        "        #self.fc_end_LPA = nn.Linear(70, 2)\n",
        "        #self.fc_end_CAA = nn.Linear(70, 7)\n",
        "        #self.fc_end_CPA = nn.Linear(70, 1)\n",
        "        self.init_form = init_form\n",
        "        if self.init_form is not None:\n",
        "            self.init()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers_stack(x)\n",
        "        T = self.fc_end_T(x)\n",
        "        #LAA = self.fc_end_LAA(x)\n",
        "        #LPA = self.fc_end_LPA(x)\n",
        "        #CAA = self.fc_end_CAA(x)\n",
        "        #CPA = self.fc_end_CPA(x)\n",
        "\n",
        "        return T #, LAA, LPA, CAA, CPA\n",
        "        \n",
        "    def init(self):\n",
        "        relu_gain = torch.nn.init.calculate_gain(\"relu\")\n",
        "        for child in self.layers_stack.children():\n",
        "            if isinstance(child, nn.Linear):\n",
        "                if self.init_form == \"normal\":\n",
        "                    torch.nn.init.kaiming_normal_(child.weight,\n",
        "                                                 nonlinearity='relu')\n",
        "                    torch.nn.init.kaiming_normal_(self.fc_end_T.weight,\n",
        "                                                 nonlinearity='relu')\n",
        "                    \n",
        "                    if child.bias is not None:\n",
        "                        torch.nn.init.zeros_(child.bias)\n",
        "                elif self.init_form == \"uniform\":\n",
        "                    torch.nn.init.kaiming_uniform_(child.weight,\n",
        "                                                  nonlinearity='relu')\n",
        "                    torch.nn.init.kaiming_uniform_(self.fc_end_T.weight,\n",
        "                                                 nonlinearity='relu')\n",
        "                    if child.bias is not None:\n",
        "                        torch.nn.init.zeros_(child.bias)\n",
        "                else:\n",
        "                    raise NotImplementedError()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6pd2yLll5Ua"
      },
      "source": [
        "### Обучение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxTp9YgUl_io"
      },
      "outputs": [],
      "source": [
        "def trainGPNN_r(model, trainloader, testloader, device = 'cpu', num_epochs = 2, criterion = nn.MSELoss,\\\n",
        "              optimizer = optim.Adam, learning_rate = 0.001, maxBatch = 10):\n",
        "\n",
        "    criterion = criterion()\n",
        "    optimizer = optimizer(model.parameters(), lr=learning_rate)\n",
        "    num_epochs = num_epochs\n",
        "    loss_hist = []\n",
        "    loss_hist_test = []\n",
        "    acc_test_1,acc_test_2,acc_test_3,acc_test_4 = [],[],[],[]\n",
        "    acc_train_1,acc_train_2,acc_train_3,acc_train_4 = [],[],[],[]\n",
        "    for epoch in range(num_epochs):\n",
        "        hist_loss = 0\n",
        "        numBatch = 0\n",
        "\n",
        "        model.train()\n",
        "        while numBatch < maxBatch:\n",
        "            corrFunc, classVectors, values = trainloader[numBatch]\n",
        "            corrFunc, classVectors, values = corrFunc.to(device),\\\n",
        "                      classVectors.to(device), values.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            predict = model(corrFunc)\n",
        "            loss = criterion(predict,values) #lossForRegression(criterion,predict,values,device)\n",
        "            #loss = lossForRegression(criterion,predict,values,device)\n",
        "            loss.backward()    \n",
        "            optimizer.step()\n",
        "            hist_loss += loss.item()\n",
        "            numBatch = numBatch + 1\n",
        "        loss_hist.append(hist_loss /len(trainloader))\n",
        "      \n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        numBatch = 0\n",
        "        with torch.no_grad():\n",
        "          while numBatch < maxBatch:\n",
        "            corrFunc, classVectors, values = testloader[numBatch]\n",
        "            predict = model(corrFunc)\n",
        "            loss = criterion(predict,values)\n",
        "            test_loss += loss.item()\n",
        "            numBatch = numBatch + 1\n",
        "        loss_hist_test.append(test_loss/len(testloader))\n",
        "        #a,b,c,d = calaculate_accuracy_classifier(model,trainloader,device)\n",
        "        #acc_train_1.append(a);acc_train_2.append(b);acc_train_3.append(c);acc_train_4.append(d)\n",
        "        #a,b,c,d = calaculate_accuracy_classifier(model,testloader,device)\n",
        "        #acc_test_1.append(a);acc_test_2.append(b);acc_test_3.append(c);acc_test_4.append(d)\n",
        "        if epoch%10 == 0: print(f\"Epoch={epoch} loss={loss_hist[epoch]:.5f} loss_test={loss_hist_test[epoch]:.5f}\")\n",
        "    return loss_hist, loss_hist_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOjW36-Qo7E4"
      },
      "outputs": [],
      "source": [
        "def lossForRegression(criterion,predict,original,device):\n",
        "  criterion = criterion\n",
        "  #подготовка к расчету loss функции, переводим данные к нужнмоу формату\n",
        "  #realT = torch.tensor([[original[0][0]]]).to(device)\n",
        "  #realLAA = torch.tensor([[original[0][0:2]]]).to(device)\n",
        "  #realLPA = torch.tensor([[original[0][3:4]]]).to(device)\n",
        "  loss_1 = []\n",
        "  for i in original:\n",
        "     loss_1.append([i[0].item(),i[1].item(),i[2].item(),i[3].item(),i[4].item(),i[5].item(),i[6].item()])\n",
        " \n",
        "  loss_1= torch.tensor(loss_1).to(device)\n",
        "\n",
        "  total_loss = criterion(predict[3],loss_1)# + criterion(predict[2],realLPA) #criterion(predict[0],loss_1)+2.*criterion(predict[1],loss_2)\n",
        "  return total_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5cskVtbkVsg"
      },
      "source": [
        "### Запуск Сети"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMu67u1c_4Qo",
        "outputId": "6adca95e-6a5c-4b5a-9738-a9ee84294106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch=0 loss=0.10903 loss_test=0.08464\n",
            "Epoch=10 loss=0.08187 loss_test=8.85782\n",
            "Epoch=20 loss=0.07997 loss_test=10.77548\n",
            "Epoch=30 loss=0.08017 loss_test=6693574.13058\n",
            "Duration: 230.4968831539154\n"
          ]
        }
      ],
      "source": [
        "manual_seed(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = GPNN_regression(init_form = 'uniform').to(device)\n",
        "model = model.float()\n",
        "time_0 = time.time()\n",
        "criterion = nn.L1Loss\n",
        "loss, loss_test = trainGPNN_r(model,trainData,\\\n",
        "                       testData, criterion = criterion, num_epochs =31, learning_rate = 0.001, device = device, maxBatch = 500)\n",
        "print(\"Duration:\", time.time()-time_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "IiomoFy2iJTd",
        "outputId": "9d2a2108-0802-4d7b-add5-6dee3758b769"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1efa5dacd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(loss)\n",
        "plt.plot(loss_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emGA4Vgetxrn",
        "outputId": "ad0a24db-c495-4ee8-fdb7-18f82aad800d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1405, 0.7713, 0.4339, 0.2567, 0.0629, 0.2254, 0.9940],\n",
              "        [0.8633, 0.7021, 0.6677, 0.8090, 0.5382, 0.2764, 0.4892],\n",
              "        [0.6472, 0.4815, 0.3239, 0.0634, 0.1337, 0.1532, 0.9611],\n",
              "        [0.2831, 0.6259, 0.7264, 0.3928, 0.0535, 0.3101, 0.9198],\n",
              "        [0.8876, 0.5130, 0.8597, 0.2498, 0.2677, 0.7376, 0.3520],\n",
              "        [0.7150, 0.6076, 0.2445, 0.7029, 0.5920, 0.3586, 0.7419],\n",
              "        [0.3450, 0.4692, 0.5850, 0.0096, 0.3494, 0.9763, 0.6097],\n",
              "        [0.7488, 0.9635, 0.4245, 0.8069, 0.0397, 0.2295, 0.6808],\n",
              "        [0.7212, 0.4971, 0.8144, 0.8714, 0.4709, 0.6147, 0.0857],\n",
              "        [0.3476, 0.5391, 0.9834, 0.3363, 0.5311, 0.1544, 0.1864]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "trainData[0][2][10:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBUpJVWdQ_Rv",
        "outputId": "8871297d-8fdb-4432-d1f8-a24103f2d560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor(0.7487, device='cuda:0'), tensor(0.3286, device='cuda:0'), tensor(0.8350, device='cuda:0'), tensor(0.1008, device='cuda:0'), tensor(0.5627, device='cuda:0'), tensor(0.5886, device='cuda:0'), tensor(0.1412, device='cuda:0'), tensor(0.2614, device='cuda:0'), tensor(0.4792, device='cuda:0'), tensor(0.9560, device='cuda:0')]\n"
          ]
        }
      ],
      "source": [
        "a = [i[4] for i in testData[0][2][0:10]]\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiIrYCpkQIU0"
      },
      "outputs": [],
      "source": [
        "a = [i[1] for i in trainData[0][2][0:500].to('cpu')]\n",
        "print(a)\n",
        "plt.hist(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEz5S7Q2uAXO",
        "outputId": "ce76a208-99dc-4641-c0dc-2baae5425b5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7791, 0.4976, 0.4167, 0.4918, 0.4962, 0.7028, 0.5582],\n",
              "        [0.8443, 0.4941, 0.2740, 0.4990, 0.4915, 0.9123, 0.5001],\n",
              "        [0.6278, 0.4931, 0.0903, 0.4983, 0.5032, 0.7217, 0.5489],\n",
              "        [0.4289, 0.4945, 0.6814, 0.4992, 0.4964, 0.5631, 0.4910],\n",
              "        [0.6845, 0.4969, 0.6728, 0.4903, 0.4957, 0.5290, 0.5889],\n",
              "        [0.8779, 0.4920, 0.3970, 0.4986, 0.4953, 0.2550, 0.5564],\n",
              "        [0.1555, 0.4945, 0.5253, 0.5092, 0.5101, 0.2227, 0.4889],\n",
              "        [0.6155, 0.4956, 0.3540, 0.4976, 0.4980, 0.6638, 0.5292],\n",
              "        [0.2074, 0.4985, 0.7126, 0.5040, 0.5012, 0.4380, 0.5723],\n",
              "        [0.8839, 0.4967, 0.5932, 0.4910, 0.4878, 0.7217, 0.5032]],\n",
              "       device='cuda:0', grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "model.eval()\n",
        "model(testData[0][0].to(device))[10:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnA9zf5M48fT"
      },
      "outputs": [],
      "source": [
        "#model(testData[0][0].to(device))[0]\n",
        "testData[0][2][:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk16mq5gRkDU",
        "outputId": "89739d6b-c499-4935-f625-94053c999601"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.018815196894109248, 0.25213289028406144, 0.037724027764052155, 0.25453245274722575, 0.25043616072833536, 0.028745856078341604, 0.25524666768312454)\n",
            "(0.018793363492935897, 0.25208011412620546, 0.03771904239431024, 0.2549823703020811, 0.24985801960527898, 0.028639005539938808, 0.2544622203707695)\n"
          ]
        }
      ],
      "source": [
        "def calaculate_accuracy_regression(model,data,device):\n",
        "  total_1, total_2 = 0., 0.\n",
        "  total_3, total_4 = 0., 0.\n",
        "  total_5,total_6,total_7= 0.0, 0.0, 0.0\n",
        "  numBatch = 0\n",
        "  model.eval()\n",
        "  while numBatch < len(data):\n",
        "    corrFunc, _, values = data[numBatch]\n",
        "    numBatch = numBatch + 1\n",
        "    corrFunc, values = corrFunc.to(device), values.to(device)\n",
        "    total_1 = total_1 + (abs(model(corrFunc)[:,0]-values[:,0])).mean().item()\n",
        "    total_2 = total_2 + (abs(model(corrFunc)[:,1]-values[:,1])).mean().item()\n",
        "    total_3 = total_3 + (abs(model(corrFunc)[:,2]-values[:,2])).mean().item()\n",
        "    total_4 = total_4 + (abs(model(corrFunc)[:,3]-values[:,3])).mean().item()\n",
        "    total_5 = total_5 + (abs(model(corrFunc)[:,4]-values[:,4])).mean().item()\n",
        "    total_6 = total_6 + (abs(model(corrFunc)[:,5]-values[:,5])).mean().item()\n",
        "    total_7 = total_7 + (abs(model(corrFunc)[:,6]-values[:,6])).mean().item()\n",
        "\n",
        "  return total_1/len(data),total_2/len(data),total_3/len(data),total_4/len(data),total_5/len(data),total_6/len(data),total_7/len(data)\n",
        "\n",
        "\n",
        "print(calaculate_accuracy_regression(model,testData,device))\n",
        "print(calaculate_accuracy_regression(model,trainData,device))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXDKi-qAsY6o"
      },
      "outputs": [],
      "source": [
        "testV = trainData[0][2].to(device)\n",
        "(abs(model(trainData[0][0])[:,0]-testV[:,0])**2).mean().item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8RBxXIokAYe"
      },
      "source": [
        "### Для визуализации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQaiLxKmkED6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_history(history, n_epochs=5, smooth_val=0.90):\n",
        "    fig, ax =  plt.subplots(3, 1, figsize=(12, 14))\n",
        "    for stage_idx, (stage_lbl, stage_title) in enumerate(\n",
        "        zip(['loss_on_train', 'loss_on_test'],\n",
        "            ['train loss', 'test loss'])):\n",
        "        # plot history on each learning step\n",
        "        epoch_len = len(history[stage_lbl])//n_epochs\n",
        "        full_stage_len = len(history[stage_lbl])\n",
        "        ax[stage_idx].plot(exponential_smoothing(history[stage_lbl], smooth_val),\n",
        "                           label='smoothed',\n",
        "                           color='m')\n",
        "        ax[stage_idx].plot(history[stage_lbl],\n",
        "                           label='raw',\n",
        "                           alpha=0.2,\n",
        "                           color='c')\n",
        "        ax[stage_idx].set_title(stage_title)\n",
        "        ax[stage_idx].set_xlabel('epochs')\n",
        "        ax[stage_idx].set_ylabel('loss')\n",
        "        epochs_ticks_positions = np.arange(stop=full_stage_len+1,\n",
        "                                           step=epoch_len)\n",
        "        ax[stage_idx].set_xticks(epochs_ticks_positions)\n",
        "        ax[stage_idx].set_xticklabels(np.arange(n_epochs+1))\n",
        "        ax[stage_idx].legend()\n",
        "\n",
        "        # plot mean train and test loss combined\n",
        "        mean_loss_on_epoch = [np.mean(history[stage_lbl][i:i+epoch_len]) \\\n",
        "                              for i in range(0, full_stage_len, epoch_len)]\n",
        "        std_loss_on_epoch = [np.std(history[stage_lbl][i:i+epoch_len]) \\\n",
        "                              for i in range(0, full_stage_len, epoch_len)]\n",
        "\n",
        "        ax[2].set_title('\\nAverage loss per epoch')\n",
        "        ax[2].errorbar(np.arange(n_epochs) + stage_idx / 30.,\n",
        "                       mean_loss_on_epoch,\n",
        "                       yerr=std_loss_on_epoch,\n",
        "                       capsize=5,\n",
        "                       fmt=\"X--\",\n",
        "                       label=stage_title)\n",
        "        ax[2].set_xticks(np.arange(5))\n",
        "        ax[2].set_xticklabels(np.arange(5))\n",
        "        ax[2].set_xlabel('epochs')\n",
        "        ax[2].set_ylabel('loss')\n",
        "        ax[2].legend()\n",
        "\n",
        "    fig.suptitle(history['model_name'], fontsize=24)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8J4bsii3ZIf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "L8RBxXIokAYe"
      ],
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}